# Ollama PDF RAG

> **Chat with your PDFs locally using Ollama and LangChain**

Welcome to the documentation for Ollama PDF RAG â€” a powerful, privacy-first application that lets you have conversations with your PDF documents using local language models.

## ğŸŒŸ Why Ollama PDF RAG?

| Feature | Benefit |
|---------|---------|
| ğŸ”’ **100% Local** | Your data never leaves your machine |
| ğŸš€ **Two UIs** | Modern Next.js app OR classic Streamlit |
| ğŸ“„ **Multi-PDF Support** | Query across multiple documents |
| ğŸ§  **Smart Retrieval** | Multi-query expansion for better results |
| âš¡ **Fast API** | FastAPI backend for production use |
| ğŸ¯ **Thinking Models** | Special support for qwen3, deepseek-r1 |

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER INTERFACE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Next.js (Modern UI)     â”‚      Streamlit (Classic)      â”‚
â”‚     localhost:3000          â”‚      localhost:8501           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FastAPI Backend                         â”‚
â”‚                      localhost:8001                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PDF Upload  â”‚  RAG Query   â”‚   Models     â”‚   Health       â”‚
â”‚  /api/v1/    â”‚  /api/v1/    â”‚   /api/v1/   â”‚   /health      â”‚
â”‚  pdfs        â”‚  query       â”‚   models     â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ChromaDB      â”‚ â”‚    Ollama       â”‚ â”‚    SQLite       â”‚
â”‚   (Vectors)     â”‚ â”‚    (LLM)        â”‚ â”‚    (Metadata)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

```bash
# 1. Clone and install
git clone <repository-url>
cd ollama_pdf_rag
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# 2. Install Ollama models
ollama pull llama3.2
ollama pull nomic-embed-text

# 3. Start the app (Next.js UI + FastAPI)
./start_all.sh
# Or manually:
# python run_api.py &
# cd web-ui && pnpm dev

# 4. Open http://localhost:3000
```

## ğŸ“– Documentation

| Section | Description |
|---------|-------------|
| [**Installation**](getting-started/installation.md) | Full setup guide |
| [**Quick Start**](getting-started/quickstart.md) | Get running in 5 minutes |
| [**PDF Processing**](user-guide/pdf-processing.md) | How documents are processed |
| [**RAG Pipeline**](user-guide/rag-pipeline.md) | Understanding retrieval |
| [**Chat Interface**](user-guide/chat-interface.md) | Using the UIs |
| [**API Reference**](api/document.md) | Backend API docs |
| [**Contributing**](development/contributing.md) | How to contribute |

## ğŸ”§ Key Features

### PDF Selection & Chat
- â˜‘ï¸ **Checkbox Selection**: Select PDFs before chatting
- ğŸ” **Question Classification**: Auto-detects if you need documents
- ğŸ’¬ **General Chat**: Works without documents too
- ğŸ“š **Multi-PDF**: Query across multiple documents

### RAG Pipeline
- ğŸ”„ **Multi-Query Retrieval**: Generates alternative queries
- ğŸ§© **Smart Chunking**: 7500 char chunks with 100 overlap
- ğŸ¯ **Source Citations**: Every answer includes sources
- ğŸ§  **Chain-of-Thought**: Thinking models show reasoning

### Developer Experience
- ğŸ“ **Type Safe**: Full TypeScript frontend
- ğŸ§ª **Tested**: Python tests with pytest
- ğŸ”„ **CI/CD**: GitHub Actions for tests
- ğŸ“š **Documented**: MkDocs with full API reference

## ğŸ“Š Project Status

Project is in active development.

## ğŸ¤ Community

- ğŸ› Report a Bug
- ğŸ’¡ Request a Feature
- ğŸ¤ [Contribute](development/contributing.md)

## ğŸ“„ License

This project is open source under the MIT License.
